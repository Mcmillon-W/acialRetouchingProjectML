# -*- coding: utf-8 -*-
"""facial_feature_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19_wCOozclRoUoSwpT97pBpNOW2WJ-7Px
"""

import cv2
import matplotlib.pyplot as plt
import dlib
import sys
import glob
import os
import numpy as np
import random
import progressbar
try:
  from PIL import Image
except:
  import Image

import os

def extract(photo):
  #print('here')
  rgb=cv2.cvtColor(photo,cv2.COLOR_BGR2RGB)
  detector = dlib.get_frontal_face_detector()
  detect=detector(photo,1)
  predictor=dlib.shape_predictor("/content/drive/My Drive/BTP/Facial_feature_landmarks/shape_predictor_68_face_landmarks.dat")
  shape=predictor(photo,detect[0])

  #left periocular
  x1=shape.part(0).x
  x2=shape.part(27).x
  y1=shape.part(19).y
  y2=shape.part(29).y
  lefteye=rgb[y1:y2,x1:x2]
  lefteye = cv2.resize(lefteye,(70,50))

  #right periocular
  x1=shape.part(27).x
  x2=shape.part(16).x
  y1=shape.part(24).y
  y2=shape.part(29).y
  righteye=rgb[y1:y2,x1:x2]
  righteye=cv2.resize(righteye,(70,50))

  #nose
  x1=shape.part(40).x
  x2=shape.part(47).x
  y1=shape.part(27).y
  y2=shape.part(33).y
  nose=rgb[y1:y2,x1:x2]
  nose=cv2.resize(nose,(64,64))

  #lips
  x1=shape.part(48).x
  x2=shape.part(54).x
  y1=shape.part(33).y
  y2=shape.part(57).y
  lips=rgb[y1:y2,x1:x2]
  lips=cv2.resize(lips,(75,45))

  #chin
  x1=shape.part(6).x
  x2=shape.part(10).x
  y1=shape.part(57).y
  y2=shape.part(8).y
  chin=rgb[y1:y2,x1:x2]
  chin=cv2.resize(chin,(80,40))

  #left cheek
  x1=shape.part(1).x
  x2=shape.part(48).x
  y1=shape.part(2).y
  y2=shape.part(5).y
  left=rgb[y1:y2,x1:x2]
  left=cv2.resize(left,(53,67))

  #right cheek
  x1=shape.part(54).x
  x2=shape.part(15).x
  y1=shape.part(14).y
  y2=shape.part(11).y
  right=rgb[y1:y2,x1:x2]
  right=cv2.resize(right,(53,67))

  
  return lefteye,righteye,nose,lips,chin,left,right


def image_to_vec(img):
  r,c,color = img.shape
  img_size = r*c*color
  vec = img.reshape(img_size)
  return vec


def read_data(path,total_samples):
  data_fp1 = np.zeros((total_samples, 3*70*50))
  data_fp2 = np.zeros((total_samples, 3*70*50))
  data_fp3 = np.zeros((total_samples, 3*64*64))
  data_fp4 = np.zeros((total_samples, 3*75*45))
  data_fp5 = np.zeros((total_samples, 3*80*40))
  data_fp6 = np.zeros((total_samples, 3*53*67))
  data_fp7 = np.zeros((total_samples, 3*53*67))
  #print(path)
  i = 0
  with progressbar.ProgressBar(max_value=total_samples) as bar:
    for file in glob.glob(path+'*'):
      photo = cv2.imread(file)
      # fp : face_patch
      fp1,fp2,fp3,fp4,fp5,fp6,fp7 = extract(photo)
      #print('here')
      data_fp1[i] = image_to_vec(fp1)
      data_fp2[i] = image_to_vec(fp2)
      data_fp3[i] = image_to_vec(fp3)
      data_fp4[i] = image_to_vec(fp4)
      data_fp5[i] = image_to_vec(fp5)
      data_fp6[i] = image_to_vec(fp6)
      data_fp7[i] = image_to_vec(fp7)
      bar.update(i)
      i += 1
  print("done!!!")
  return data_fp1,data_fp2,data_fp3,data_fp4,data_fp5,data_fp6,data_fp7


def train(path1,path2,total_original,total_retouched,labels):
  # fp : face_patch
  print("Extracting facial features from images(original)")
  fp10,fp20,fp30,fp40,fp50,fp60,fp70 = read_data(path1,total_original)
  print("Extracting facial features from images(retouched)")
  fp11,fp21,fp31,fp41,fp51,fp61,fp71 = read_data(path2,total_retouched)
  fp1 = np.concatenate((fp10,fp11),axis=0) # n*D1
  fp2 = np.concatenate((fp20,fp21),axis=0) # n*D2
  fp3 = np.concatenate((fp30,fp31),axis=0) # n*D3
  fp4 = np.concatenate((fp40,fp41),axis=0) # n*D4
  fp5 = np.concatenate((fp50,fp51),axis=0) # n*D5
  fp6 = np.concatenate((fp60,fp61),axis=0) # n*D6
  fp7 = np.concatenate((fp70,fp71),axis=0) # n*D7

  concat_results = np.concatenate((fp1,fp2,fp3,fp4,fp5,fp6,fp7),axis=1)
  input_to_SVM = concat_results

  return input_to_SVM


def output_SRBMS(path1, path2,total_original,total_retouched):
  label_to_SVM = np.concatenate((np.zeros((total_original,1)),np.ones((total_retouched,1))), axis=0) # n*1 
  input_to_SVM = train(path1, path2, total_original, total_retouched,label_to_SVM) #n*D
  print("total_samples: ", input_to_SVM.shape[0])
  print("feature_per_sample:", input_to_SVM.shape[1])
  return input_to_SVM, label_to_SVM