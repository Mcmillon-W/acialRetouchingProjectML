{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRBM_implementation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"s15FptP6D3WD","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/BTP/codes')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qe12DBGVenhQ","colab_type":"code","colab":{}},"source":["import sklearn\n","from sklearn.model_selection import  train_test_split\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.svm import SVC\n","import numpy as np\n","import pandas as pd \n","import cv2\n","import facial_feature_extraction\n","import glob\n","import progressbar\n","import pickle\n","import seaborn as sns\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import srbm\n","from sklearn.multiclass import OneVsOneClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NTAWaeFufSZg","colab_type":"text"},"source":["### Restricted Botzmann Machine"]},{"cell_type":"code","metadata":{"id":"e-KKXllgfRKj","colab_type":"code","colab":{}},"source":["class RbmImpl:\n","    # constructor\n","    def __init__(self, num_visible, num_hidden, bool_ver):\n","        self.num_hidden = num_hidden\n","        self.num_visible = num_visible\n","        self.verbose = bool_ver\n","        np_rng = np.random.RandomState(3412)\n","\n","        # initialize random weights\n","        self.weights = np.asarray(np_rng.uniform(\n","                    low=-4 * np.sqrt(6. / (num_hidden + num_visible)),\n","                    high=4 * np.sqrt(6. / (num_hidden + num_visible)),\n","                    size=(num_visible, num_hidden)))\n","\n","        # add one as first row and first column\n","        self.weights = np.insert(self.weights, 0, 0, axis = 0)\n","        self.weights = np.insert(self.weights, 0, 0, axis = 1)\n","\n","\n","    # training code\n","    def train_rbm(self, data, max_epochs = 2000, learning_rate = 0.08):\n","        # N = number_samples, D = number_visible_units, H = number_hidden_units\n","        # data or X is N*D, weights or W is (D+1)*(H+1)\n","        num_examples = data.shape[0] # sample size\n","        \n","        # insert 1 as the first column\n","        data = np.insert(data, 0, 1, axis = 1) # N * (D+1)\n","        with progressbar.ProgressBar(max_value=max_epochs) as bar:\n","            for epoch in range(max_epochs):\n","                #print(epoch,max_epochs)\n","                pos_hid_activations = np.dot(data, self.weights) # X * W  ( size = n * (H+1) )\n","                pos_hid_probs = self.sigmoid(pos_hid_activations) # f(XW) => activation  ( size = n * (H+1) )\n","                pos_hid_probs[:,0] = 1 # set bias term to one\n","                pos_hid_states = pos_hid_probs > np.random.rand(num_examples,self.num_hidden + 1) # check great than random weights_(n*H+1)\n","                pos_associations = np.dot(data.T, pos_hid_probs) # X' * f(XW)  ( size = (D+1)*(H+1) )\n","\n","                # pos_hid_states back to the visible units\n","                neg_vis_activations = np.dot(pos_hid_states, self.weights.T) # n * (D+1)\n","                neg_vis_probs = self.sigmoid(neg_vis_activations) # n * (D+1)\n","                neg_vis_probs[:,0] = 1 # set bias term to one\n","\n","                neg_hid_activations = np.dot(neg_vis_probs, self.weights) # n * (H+1)\n","                neg_hid_probs = self.sigmoid(neg_hid_activations) # n * (H+1)\n","                neg_associations = np.dot(neg_vis_probs.T, neg_hid_probs) # (D+1) * (H+1)\n","\n","                # weight updation equation \n","                self.weights += learning_rate * ((pos_associations - neg_associations) / num_examples) \n","\n","                # calculate L2 error \n","                error = np.sum((data - neg_vis_probs) ** 2)\n","                if self.verbose:\n","                    print('Epoch '+str(epoch)+' : Error is: '+str(error))\n","                \n","                bar.update(epoch)\n","\n","    #  sigmoid activation function         \n","    def sigmoid(self, val):\n","        return 1.0 / (1 + np.exp(-val))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQC8sE8Bxc8I","colab_type":"code","colab":{}},"source":["# print bool array\n","def bool_arr(arr):\n","  for i in range(arr.shape[0]):\n","    for j in range(arr.shape[1]):\n","      arr[i,j]=1 if arr[i,j]>=0.5 else 0\n","  return arr"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-in_rmWfsVA","colab_type":"text"},"source":["### Run"]},{"cell_type":"code","metadata":{"id":"0qVBPYd9Ftx3","colab_type":"code","colab":{}},"source":["def train_util(data):\n","  rbmInstance = RbmImpl(data.shape[1],100,False)\n","  rbmInstance.train_rbm(data = data, max_epochs = 100)\n","  W = rbmInstance.weights\n","  data = np.insert(data, 0, 1, axis = 1) # add one as first column\n","  Hid = rbmInstance.sigmoid( np.dot(data,W) ) # n * (H+1)\n","  Result = Hid[:,1:] # ignore first biased term\n","  print(\".................................................\")\n","  return Result,W"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BruN6CzgEqCT","colab_type":"code","colab":{}},"source":["def train_data(path1,path2,total_original,total_retouched):\n","  print(\"Extracting facial features from images(original)\")\n","  fp10,fp20,fp30,fp40,fp50,fp60,fp70 = facial_feature_extraction.read_data(path1,total_original)\n","  print(\"Extracting facial features from images(retouched)\")\n","  fp11,fp21,fp31,fp41,fp51,fp61,fp71 = facial_feature_extraction.read_data(path2,total_retouched)\n","  fp1 = np.concatenate((fp10,fp11),axis=0) # n*D1\n","  fp2 = np.concatenate((fp20,fp21),axis=0) # n*D2\n","  fp3 = np.concatenate((fp30,fp31),axis=0) # n*D3\n","  fp4 = np.concatenate((fp40,fp41),axis=0) # n*D4\n","  fp5 = np.concatenate((fp50,fp51),axis=0) # n*D5\n","  fp6 = np.concatenate((fp60,fp61),axis=0) # n*D6\n","  fp7 = np.concatenate((fp70,fp71),axis=0) # n*D7\n","  a1,W1 = train_util(fp1)\n","  a2,W2 = train_util(fp2)\n","  a3,W3 = train_util(fp3)\n","  a4,W4 = train_util(fp4)\n","  a5,W5 = train_util(fp5)\n","  a6,W6 = train_util(fp6)\n","  a7,W7 = train_util(fp7)\n","  input_to_svm = np.concatenate((a1,a2,a3,a4,a5,a6,a7),axis=1)\n","  label_to_SVM = np.concatenate((np.zeros((total_original,1)),np.ones((total_retouched,1))), axis=0) # n*1 \n","  return input_to_svm,label_to_SVM,W1,W2,W3,W4,W5,W6,W7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmndAwJ2G_Hc","colab_type":"code","colab":{}},"source":["def test(path1,path2,total_original,total_retouched):\n","  label_to_SVM = np.concatenate((np.zeros((total_original,1)),np.ones((total_retouched,1))), axis=0) # n*1 \n","  # fp : face_patch\n","  print(\"Extracting facial features from images(original)\")\n","  fp10,fp20,fp30,fp40,fp50,fp60,fp70 = facial_feature_extraction.read_data(path1,total_original)\n","  print(\"Extracting facial features from images(retouched)\")\n","  fp11,fp21,fp31,fp41,fp51,fp61,fp71 = facial_feature_extraction.read_data(path2,total_retouched)\n","  fp1 = np.concatenate((fp10,fp11),axis=0) # n*D1\n","  fp2 = np.concatenate((fp20,fp21),axis=0) # n*D2\n","  fp3 = np.concatenate((fp30,fp31),axis=0) # n*D3\n","  fp4 = np.concatenate((fp40,fp41),axis=0) # n*D4\n","  fp5 = np.concatenate((fp50,fp51),axis=0) # n*D5\n","  fp6 = np.concatenate((fp60,fp61),axis=0) # n*D6\n","  fp7 = np.concatenate((fp70,fp71),axis=0) # n*D7\n","  \n","  return fp1,fp2,fp3,fp4,fp5,fp6,fp7,label_to_SVM"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2ItxwTrjmbj","colab_type":"code","colab":{}},"source":["def get_input(path1,path2):\n","  c1=0\n","  for file in glob.glob(path1+'*'):\n","    c1 += 1\n","  c2=0\n","  for file in glob.glob(path2+'*'):\n","    c2 += 1\n","  X,Y,W1,W2,W3,W4,W5,W6,W7 = train_data(path1,path2,c1,c2)\n","  return X,Y,W1,W2,W3,W4,W5,W6,W7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocKS-J0_Jl8q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":390},"outputId":"c9d1c74d-ebd2-4cbf-8d85-f2fbe8475b22","executionInfo":{"status":"ok","timestamp":1591542647508,"user_tz":-330,"elapsed":788683,"user":{"displayName":"KAMAL SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIMpUrLtsHTuxkD0kF4-AWwiTDJPzyf5iV6Aq74Q=s64","userId":"02402984487864416881"}}},"source":["path1 = '/content/drive/My Drive/BTP/Dataset/celebrity_dataset/original/' # path to original images\n","path2 = '/content/drive/My Drive/BTP/Dataset/celebrity_dataset/photoshopped/' # path to retouched images\n","X,Y,W1,W2,W3,W4,W5,W6,W7 = get_input(path1,path2)\n","X_train, X_val, y_train, y_val = train_test_split(X, Y.ravel(), test_size=0.2, shuffle=True)\n","\n","C_reg = [0.1, 0.3, 1, 3, 10, 30, 100, 300]\n","max_acc = 0\n","i = 0\n","save_i = 0\n","for c in C_reg:\n","  model = SVC(kernel='rbf', C=c)\n","  clf = model.fit(X_train,y_train)\n","  acc = clf.score(X_val,y_val)\n","  y_pred = clf.predict(X_val)\n","  if max_acc <= acc:\n","    max_acc = acc\n","    save_i = i\n","  i += 1"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Extracting facial features from images(original)\n"],"name":"stdout"},{"output_type":"stream","text":["100% (160 of 160) |######################| Elapsed Time: 0:04:26 Time:  0:04:26\n"],"name":"stderr"},{"output_type":"stream","text":["done!!!\n","Extracting facial features from images(retouched)\n"],"name":"stdout"},{"output_type":"stream","text":["100% (160 of 160) |######################| Elapsed Time: 0:04:32 Time:  0:04:32\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: RuntimeWarning: overflow encountered in exp\n"],"name":"stderr"},{"output_type":"stream","text":["done!!!\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:34 Time:  0:00:34\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:34 Time:  0:00:34\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:39 Time:  0:00:39\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:32 Time:  0:00:32\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:31 Time:  0:00:31\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:34 Time:  0:00:34\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"},{"output_type":"stream","text":["100% (100 of 100) |######################| Elapsed Time: 0:00:34 Time:  0:00:34\n"],"name":"stderr"},{"output_type":"stream","text":[".................................................\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sS9NfUmcSHJN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":464},"outputId":"f60f1a17-7c8f-4ba1-c10a-db88fa25c202","executionInfo":{"status":"ok","timestamp":1591543047091,"user_tz":-330,"elapsed":1438,"user":{"displayName":"KAMAL SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIMpUrLtsHTuxkD0kF4-AWwiTDJPzyf5iV6Aq74Q=s64","userId":"02402984487864416881"}}},"source":["model = SVC(kernel='rbf', C=C_reg[save_i])\n","# save model\n","os.chdir('/content/drive/My Drive/BTP/trained_models/')\n","filename  = 'SVM_FF.sav'\n","pickle.dump(clf, open(filename, 'wb'))\n","loaded_model = pickle.load(open('SVM_FF.sav', 'rb'))\n","acc = loaded_model.score(X_val,y_val)\n","y_pred = loaded_model.predict(X_val)\n","cnf = sns.heatmap(confusion_matrix(y_val, y_pred), cmap=\"YlGnBu\", annot=True)\n","\n","print(\"classification report\\n\")\n","print(classification_report(y_val,y_pred))"],"execution_count":78,"outputs":[{"output_type":"stream","text":["classification report\n","\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.88      0.84        40\n","         1.0       0.76      0.67      0.71        24\n","\n","    accuracy                           0.80        64\n","   macro avg       0.79      0.77      0.78        64\n","weighted avg       0.79      0.80      0.79        64\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}